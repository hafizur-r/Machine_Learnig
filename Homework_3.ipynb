{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework-3\n",
    "### CSC-722: Machine Learning Fundamentals\n",
    "### Md Hafizur Rahman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes https://heartbeat.fritz.ai/naive-bayes-classifier-in-python-using-scikit-learn-13c4deb83bcf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(1) Explain your observation\n",
    "(2) Explain the code\n",
    "(3) Explain why training phase accuracy is better than testing accuracy.\n",
    "(4) Explain what happens to test and training accuracy when test_size increases/decreases. change it to 0.1, 0.3, 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) My observation:\n",
    "\n",
    "## Problem Statement:  \n",
    "We have information on glucose, blood pressure, and diabetes values either 0 or 1 (in this case, 0 means they don't have diabetes and 1 means they have diabetes) of 995 patients. The information of all patients is stored in \"Naive-Bayes-Classification-Data.csv\" file. Our goal is to find a patient who has diabetes or not. Solve this classification problem by using the Naive Bayes classifier.\n",
    "\n",
    "### Solution:\n",
    "If P(A) the probability that A is true, P(B) the probability that B is true, and P(B|A) the probability that B is true given that A is true then accroding to the Naive Bayes P(A|B) (the probability that A is true given that B is true) can write as:\n",
    "                                                \n",
    "                                                P(A|B)={P(B|A)*P(A)}/P(B)\n",
    "\n",
    "In our case, the inputs are glucose and blood pressure and the output is either have diabetes or don't have diabetes. We have to classify a patients have diabetes or not. Let assume, the output classes are diab and no_diab and inputs are gluc and bldpre. \n",
    "We have to determine that \n",
    "For having diabetes,\n",
    "    \n",
    "                P(diab|gluc,bldpre)={P(diab)*P(gluc|diab)*P(bldpre|gluc,diab)}/P(gluc,bldpre)\n",
    "\n",
    "Let assigen diab=C, gluc=A and bldpre=B. The above equation became:\n",
    "\n",
    "                P(C|A,B)={P(C)*P(B|C)*P(A|B,C)}/P(A,B)\n",
    "                \n",
    "We naviely assume A and B are independent. Then above equatiob became:\n",
    "\n",
    "                P(C|A,B)={P(C)*P(B|C)*P(A|C)}/P(A,B)--------(1)\n",
    "                \n",
    "Similarly, for don't have diabetes, assume no_diab=D,\n",
    "\n",
    "                P(D|A,B)={P(D)*P(B|D)*P(A|D)}/P(A,B)--------(2)\n",
    "                \n",
    "Now, we have compare equations (1) and (2) to determine the class.\n",
    "\n",
    "                {P(C)*P(B|C)*P(A|C)}/P(A,B) \">or<\" {P(D)*P(B|D)*P(A|D)}/P(A,B)\n",
    "                => P(C)*P(B|C)*P(A|C) \">or<\" P(D)*P(B|D)*P(A|D) -------------(3)\n",
    "\n",
    "We don't know the prior information of P(C) and P(D). Let consider, P(C)=P(D)=0.5, then we can write the equation (3) as follows:\n",
    "\n",
    "                P(B|C)*P(A|C) \">or<\" P(B|D)*P(A|D)\n",
    "              \n",
    "              => P(bldpre|diab)*P(gluc|diab) \">or<\" P(bldpre|no_diab)*P(gluc|no_diab)\n",
    "                \n",
    "We will get the velues of P(bldpre|diab), P(gluc|diab), P(bldpre|no_diab), and P(gluc|no_diab) from the train data. Then we can say that a patient have diabetes or not with the given values of glucose and bloodpressure.\n",
    "\n",
    "This is implemented in Python programing language. The implementation steps have explained by follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Code Explanation\n",
    "At first, we import the necessary libraries. we’re going to use scikit-learn to implement the naive Bayes classifier model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the libraries are imported, our next step is to load the data using the read_csv method of Pandas into a Pandas data frame df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Naive-Bayes-Classification-Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the data of glucose and bloodpressure in x, which is the input of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glucose  bloodpressure\n",
      "0         40             85\n",
      "1         40             92\n",
      "2         45             63\n",
      "3         45             80\n",
      "4         40             73\n",
      "..       ...            ...\n",
      "990       45             87\n",
      "991       40             83\n",
      "992       40             83\n",
      "993       40             60\n",
      "994       45             82\n",
      "\n",
      "[995 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "x = df.drop('diabetes', axis = 1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before feeding the data to the naive Bayes classifier model, we need to do some pre-processing. \n",
    "At first, we store the diabetes values of df in y, which is the output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['diabetes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the x and y variables by taking them from the datase, we are using the \"train_test_split\" function of scikit-learn to split the data into training and test sets.\n",
    "Finally, the test size of 0.25 indicates we’ve used 25% of the data for testing. \"random_state ensures\" reproducibility. For the output of train_test_split, we get x_train, x_test, y_train, and y_test values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = .25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes, we deal with continuous features, and Gaussian means it’s assumed that the continuous values associated with each class are distributed according to a normal distribution. Suppose the training data contains a continuous feature A—let’s divide the feature data by the class and then find the mean and variance of x in each class—this should end up as a normal distribution. The parameters like priors and var_smoothing for the model. All these parameters are configurable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completeing the training, the model is ready to make predictions. We can use the predict method on the model and pass x_test as a parameter to get the output as y_pred. The prediction output is an array of either 0 or 1 corresponding to the input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0\n",
      " 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1\n",
      " 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0\n",
      " 1 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can check to see how well our model is performing on the test data. For this, we evaluate our model by finding the accuracy score produced by the model. The model accuracy on test data is 92.77%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.7710843373494\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_predict)*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also check the training accuracy. The model training accuracy on test data is 93.56%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.5656836461126\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_train)\n",
    "accuracy = accuracy_score(y_train, y_predict)*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Why training phase accuracy is better than testing accuracy?\n",
    "\n",
    "### My observation: \n",
    "The main reasons are the features variance of the test data is higher than the training data. If features of a dataset is not closer to liner, the accuracy will decrease. For that reason, we got lower testing accuracy than that training phase accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) What happens to test and training accuracy when test_size increases/decreases. change it to 0.1, 0.3, 0.4?\n",
    "\n",
    "### For test_size=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.1, random_state = 42)\n",
    "model = GaussianNB()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuarcy:  91.0\n",
      "Training Accuarcy:  93.63128491620112\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)*100\n",
    "print(\"Test Accuarcy: \", accuracy)\n",
    "y_predict = model.predict(x_train)\n",
    "accuracy_ = accuracy_score(y_train, y_predict)*100\n",
    "print(\"Training Accuarcy: \", accuracy_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After decreasing the test data,  we are seeing that test accuracy is decreased from 92.77% to 91%. However, we didn't change the training dataset, the accuracy of training dataset doesn't change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For test_size=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 42)\n",
    "model = GaussianNB()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuarcy:  93.31103678929766\n",
      "Training Accuarcy:  93.39080459770115\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)*100\n",
    "print(\"Test Accuarcy: \", accuracy)\n",
    "y_predict = model.predict(x_train)\n",
    "accuracy_ = accuracy_score(y_train, y_predict)*100\n",
    "print(\"Training Accuarcy: \", accuracy_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After increasing the test data, we are seeing that test accuracy is increased from 91% to 93.311%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For test_size=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.4, random_state = 42)\n",
    "model = GaussianNB()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuarcy:  92.96482412060301\n",
      "Training Accuarcy:  93.63484087102178\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)*100\n",
    "print(\"Test Accuarcy: \", accuracy)\n",
    "y_predict = model.predict(x_train)\n",
    "accuracy_ = accuracy_score(y_train, y_predict)*100\n",
    "print(\"Training Accuarcy: \", accuracy_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further increasing the test data, we are seeing that test accuracy is decreased from 93.311% to 92.965%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the code please click the following link:\n",
    "\n",
    "https://github.com/hafizurr/Machine_Learnig_course/blob/master/home_work/Homework_3.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
